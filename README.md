# AISOC Season 1 Sequel Tracks
Sequel to the successful first edition of AISOC in 2024, and based on popular demand, we are opening the following specialist tracks to help you advance and specialize your knowledge and skill in specific areas of interest.
- Building Scalable Agentic Workflows
- Training, Serving, Scaling and Debugging LLMs
- AI Systems in Production (Models, RAGs, Agents)

These tracks are largely independent of each other, however, they do have strict prerequisites as outlined in their respective sections. Intending participants must ensure they meet these requirements.

**These tracks are not for complete beginners to AI or LLMs!**

## Track 1: Building Scalable Agentic Workflows
### Overview
Hands-on technical training in the principles and best practices of designing and implementing LLM agents. This is a deep dive and more comprehensive treatment of the folowing sessions on Agents from Season 1:
- [Introduction to Pydantic, Data Validation & Structured Outputs for LLMs](https://github.com/ai-summer-of-code/aisoc-season-1/tree/main/src/week_1/day_3_pydantic)
- [Turning LLMs into Agentic Systems](https://github.com/ai-summer-of-code/aisoc-season-1/tree/main/src/week_2/day_1_agents)
- [Building Conversational Web Search Agents](https://github.com/ai-summer-of-code/aisoc-season-1/tree/main/src/week_2/day_3_web_search/src/agent)

### Track Details
**Instructors:** Sam Ayo, Zion Pibowei

**Target Audience:** AISOC Season 1 graduates or anyone who has at least foundational knowledge prototyping LLM systems such as QA systems and RAG. This track is not for beginers in AI or LLMs.

**Prerequisites:**
- Working knowledge of Python or similar programming languages.
- Familiarity with LLM APIs such as OpenAI, Gemini, Claude, etc, for prototyping.
- At least basic knowledge of prompt engineering

**Timeline:** Februrary 28 - March 9, 2025

### Delivery Mode
- **Online:** Live sessions for ALL particpants.
- **In-person:** Bonus physical sessions on Saturdays to be held in Lagos for those interested. Venue and schedule TBA.

### Curriculum Structure
Coming soon!

## Track 2: Training, Serving, Scaling and Debugging LLMs
### Overview
Hands-on technical training in the inner-workings of large language models - from LLM architectures and training/finetuning techniques to deployment. You will learn how to pretrain LLMs on GPUs, finetune existing LLMs, serve LLMs based on infrastructure capacity or available compute, and finally how to optimise LLM servers using techniques such as distributed inference and server autoscaling.

### Track Details
**Instructors:** Zion Pibowei. Other instructors to be announced soon.

**Target Audience:** AISOC Season 1 graduates or anyone who has at least foundational knowledge prototyping LLM systems such as QA systems and RAG. This track is not for beginers in AI or LLMs.

**Prerequisites:**
- Working knowledge of Python. Experience with Pytorch will be a bonus.
- Familiarity with LLM APIs such as OpenAI, Gemini, Claude, etc, for prototyping.
- At least basic knowledge of prompt engineering
- Previous experience training classical machine learning and deep learning models will be a bonus but not compulsory.
- Familiarity with GPUs, CUDA and HuggingFace will be a bonus!

**Timeline:** March 21 - April 6, 2025

### Delivery Mode
- **Online:** Live sessions for ALL particpants
- **In-person:** Bonus physical sessions on Saturdays to be held in Lagos for those interested. Venue and schedule TBA.

### Curriculum Structure
Coming soon!







